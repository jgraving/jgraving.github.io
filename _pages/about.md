---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
  - /about
---

Hi, I’m Jake 👋 — I’m currently a Research Scientist at the [Max Planck Institute of Animal Behavior](https://www.ab.mpg.de/), working at the intersection of AI, data science, and animal behavior.

I build scalable, interpretable tools for collecting and analyzing behavioral data, across both lab and field settings. My work draws from machine learning, computer vision, probabilistic programming, and Bayesian inference to uncover structure in complex systems.

My research is highly interdisciplinary — I collaborate with neuroscientists, biologists, physicists, and engineers to develop end-to-end pipelines spanning experimental design, data collection, and computational analysis.

A central focus of my work is building AI systems that *go beyond prediction* — tools that help test hypotheses, reveal mechanisms, and support scientific understanding — with the goal of turning computational insights into scientific discoveries.

👇 Check out some of my projects below:

# Projects

## 🦗 **Collective Motion in Locusts**  
Analyzed behavioral data from lab and virtual reality experiments to test a mechanistic model of swarming. I developed a Bayesian model that helps explain collective motion in locusts, showing that:

- Locusts don’t align with neighbors as classical models suggest.  
- Collective motion arises from internal decision-making and neural representations of neighbors.  

### 🔗 **Links**  
[Publication](https://www.science.org/doi/10.1126/science.adq7832) · [Perspective](https://doi.org/10.1126/science.adw0733) · [Feature Article](https://www.campus.uni-konstanz.de/en/science/scientists-rewrite-the-rules-of-swarming-locusts) · [Model Code](https://github.com/jgraving/sayin_locust_mixture_model)

### 📄 **Citation**  
> Sayin, S., Couzin-Fuchs, E., Petelski, I., Günzel, Y., Salahshour, M., Lee, C.-Y., **Graving, J.M.**, Li, L., Deussen, O., Couzin, I.D., et al. (2025). *The behavioral mechanisms governing collective motion in swarming locusts.* **Science**, 387(6737), 995–1000. [https://doi.org/10.1126/science.adq7832](https://www.science.org/doi/10.1126/science.adq7832)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; width: 85%; max-width: 100%; margin: 1em auto;">
  <iframe src="https://www.youtube.com/embed/oBJnY4HKmeY" 
          style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
          frameborder="0" allowfullscreen>
  </iframe>
</div>


## 🛸 **Quantifying Group Movement Using Drones and AI**  
Built the *first-of-its-kind* computer vision pipeline to extract 3D movement and environmental data from drone footage of wild animal groups. I contributed models and analysis to track individuals and reconstruct group behavior in complex natural settings.

- Combines drone video with deep learning–based detection and tracking  
- Enables large-scale, non-invasive observation of social behavior in the wild  

### 🔗 **Links**  
[Code on GitHub](https://github.com/benkoger/overhead-video-worked-examples) · [Publication](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904) · [Press Release](https://www.biologie.uni-konstanz.de/fachbereich/aktuelles/details/observing-group-living-animals-with-drones-and-computer-vision/) · [Feature Article](https://www.campus.uni-konstanz.de/en/science/observing-group-living-animals-with-drones-and-computer-vision) · [HerdHover Project](https://herdhover.com/)

### 📄 **Citation**  
> Koger, B., Deshpande, A., Kerby, J.T., **Graving, J.M.**, Costelloe, B.R., & Couzin, I.D. (2023). *Quantifying the movement, behaviour and environmental context of group-living animals using drones and computer vision.* **Journal of Animal Ecology**, 92(7), 1498–1515. [https://doi.org/10.1111/1365-2656.13904](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904)

<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/tracks_on_map_observation088.png" alt="Animal Tracks on Map" style="width:100%; margin-top:10px;">


## 🐟 **Vortex Phase Matching in Schooling Fish**  
Used deep learning–based pose estimation to test predictions from robotic models of energy-efficient schooling. I helped analyze fish movement to validate a vortex-phase matching strategy originally observed in robots.  

### 🔗 **Links**  
[Publication](https://www.nature.com/articles/s41467-020-19086-0) · [Press Release](https://www.uni-konstanz.de/en/university/news-and-media/current-announcements/news-in-detail/roboter-helfen/)

### 📄 **Citation**  
> Li, L., Nagy, M., **Graving, J.M.**, Bak-Coleman, J., Xie, G., & Couzin, I.D. (2020). *Vortex phase matching as a strategy for schooling in robots and in fish.* **Nature Communications**, 11, Article 5408. [https://doi.org/10.1038/s41467-020-19086-0](https://www.nature.com/articles/s41467-020-19086-0)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; width: 85%; max-width: 100%; margin: 1em auto;">
  <iframe src="https://www.youtube.com/embed/J4T4hi8RO7s" 
          style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
          frameborder="0" allowfullscreen>
  </iframe>
</div>


## 🤸‍♂️ **DeepPoseKit**  
Created an open-source toolkit for animal pose estimation using deep learning. The models support fast, accurate posture tracking across species — even with small datasets.  

### 🔗 **Links**  
[Code on GitHub](https://github.com/jgraving/DeepPoseKit) · [Publication](https://elifesciences.org/articles/47994) · [Feature Article](https://www.campus.uni-konstanz.de/en/science/new-method-improves-measurement-of-animal-behaviour-using-deep-learning)

### 📰 **Featured In**  
[Quanta Magazine](https://www.quantamagazine.org/to-decode-the-brain-scientists-automate-the-study-of-behavior-20191210/) · [Nature Methods](https://doi.org/10.1038/s41592-019-0678-2) · [Nature News & Views](https://doi.org/10.1038/d41586-019-02942-5)

### 📄 **Citation**  
> **Graving, J.M.**, Chae, D., Naik, H., Li, L., Koger, B., Costelloe, B.R., Couzin, I.D. (2019). *DeepPoseKit, a software toolkit for fast and robust animal pose estimation using deep learning.* **eLife**, 8, e47994. [https://doi.org/10.7554/eLife.47994](https://elifesciences.org/articles/47994)

<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/Figure1video1.gif" alt="Swarm Pose" style="width:100%; margin-top:10px;">


## 🐦 **Automated Barcode Tracking in Birds**  
Helped build a low-cost system for tracking individual zebra finches using backpack-mounted barcodes. The pipeline enables automated identification, position, and orientation tracking — supporting long-term, fine-scale studies of behavior and social networks.  

### 🔗 **Links**  
[Publication](https://doi.org/10.1111/2041-210X.13005)

### 📄 **Citation**  
> Alarcón-Nieto, G., **Graving, J.M.**, Klarevas-Irby, J.A., Maldonado-Chaparro, A.A., Mueller, I., & Farine, D.R. (2018). *An automated barcode tracking system for behavioural studies in birds.* **Methods in Ecology and Evolution**, 9(6), 1536–1547. [https://doi.org/10.1111/2041-210X.13005](https://doi.org/10.1111/2041-210X.13005)

<div style="text-align: center;">
  <video width="85%" controls>
    <source src="https://github.com/jgraving/jgraving.github.io/raw/master/files/videos/zebra_finches_tracked.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
</div>


## 🕷 **Navigation in Whip Spiders**  
Led lab and field experiments on spatial behavior and sensory integration in whip spiders. We used radio telemetry, sensory manipulation, and behavioral tracking to study how these nocturnal arachnids navigate complex environments.

- Demonstrated goal-directed navigation without vision  
- Showed that antenniform legs provide key tactile and olfactory cues  

### 🔗 **Links**  
[Journal of Experimental Biology (2017)](https://doi.org/10.1242/jeb.149823) · [Journal of Comparative Physiology A (2017)](https://doi.org/10.1007/s00359-017-1169-5) · [Frontiers in Behavioral Neuroscience (2016)](https://doi.org/10.3389/fnbeh.2016.00047)

### 📄 **Citations**  
> **Graving, J.M.**, Bingman, V.P., Hebets, E.A., & Wiegmann, D.D. (2017). *Development of site fidelity in the nocturnal amblypygid, Phrynus marginemaculatus.* **Journal of Comparative Physiology A**, 203, 313–328. [https://doi.org/10.1007/s00359-017-1169-5](https://doi.org/10.1007/s00359-017-1169-5)  
>  
> Bingman, V.P., **Graving, J.M.**, Hebets, E.A., & Wiegmann, D.D. (2017). *Importance of the antenniform legs, but not vision, for homing by the neotropical whip spider Paraphrynus laevifrons.* **Journal of Experimental Biology**, 220, 885–890. [https://doi.org/10.1242/jeb.149823](https://doi.org/10.1242/jeb.149823)  
>  
> Wiegmann, D.D., Hebets, E.A., Gronenberg, W., **Graving, J.M.**, & Bingman, V.P. (2016). *Amblypygids: Model organisms for the study of arthropod navigation mechanisms in complex environments?* **Frontiers in Behavioral Neuroscience**, 10:47. [https://doi.org/10.3389/fnbeh.2016.00047](https://doi.org/10.3389/fnbeh.2016.00047)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; width: 85%; max-width: 100%; margin: 1em auto;">
  <iframe src="https://www.youtube.com/embed/6hY8X-qwyiU" 
          style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
          frameborder="0" allowfullscreen>
  </iframe>
</div>

<!-- 
Optional additional gifs:
<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/zebra.gif" alt="Zebra Pose Estimation" style="width:25%;">
<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/locust.gif" alt="Locust Pose Estimation" style="width:25%;">
-->
