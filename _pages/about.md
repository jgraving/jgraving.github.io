---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
  - /about
---

Hi, Iâ€™m Jake ðŸ‘‹ â€” I'm currently a Research Scientist at the [Max Planck Institute of Animal Behavior](https://www.ab.mpg.de/), where I work at the intersection of AI and behavioral science.

I build interpretable and scalable machine learning tools â€” often grounded in modern AI and deep learning â€” to study animal behavior across both lab and field settings. I develop methods that draw from computer vision, probabilistic programming, self-supervised learning, and Bayesian causal inference, with the goal of measuring and making sense of behavioral data.

My work is deeply interdisciplinary. I collaborate with physicists, neuroscientists, field biologists, and engineers to design end-to-end pipelines that span experimental design, data collection, and computational analysis.

Iâ€™m particularly interested in AI systems that go beyond prediction â€” tools that support scientific inference by uncovering mechanisms, testing hypotheses, and explaining the structure and dynamics of complex systems. While much of my work focuses on behavior, Iâ€™m broadly motivated by questions at the interface of data, theory, and explanation across the natural sciences.

# Projects

## ðŸ¦— **Collective Motion in Locusts**  
Bayesian modeling and statistical analysis of VR behavioral data to reveal the mechanisms governing collective motion in swarming locusts.  
ðŸ”— [Publication](https://www.science.org/doi/10.1126/science.adq7832) | [Perspective](https://doi.org/10.1126/science.adw0733) | [Press Release](https://www.campus.uni-konstanz.de/en/science/scientists-rewrite-the-rules-of-swarming-locusts) | [Model Code](https://github.com/jgraving/sayin_locust_mixture_model)  
**ðŸ“„ Citation:**  
> Sayin, S., Couzin-Fuchs, E., Petelski, I., GÃ¼nzel, Y., Salahshour, M., Lee, C.-Y., **Graving, J.M.**, Li, L., Deussen, O., Couzin, I.D., et al. (2025). *The behavioral mechanisms governing collective motion in swarming locusts.* **Science**, 387(6737), 995â€“1000. [https://doi.org/10.1126/science.adq7832](https://www.science.org/doi/10.1126/science.adq7832)


## ðŸ›¸ **Quantifying Group Movement Using Drones and AI**  
A computer vision pipeline combining drone footage and deep learning to extract 3D behavioral and environmental data for animal groups in the wild.  
ðŸ”— [Code on GitHub](https://github.com/benkoger/overhead-video-worked-examples) | [Publication](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904) | [Press Release](https://www.biologie.uni-konstanz.de/fachbereich/aktuelles/details/observing-group-living-animals-with-drones-and-computer-vision/) | [HerdHover Project](https://herdhover.com/)  
**ðŸ“„ Citation:**  
> Koger, B., Deshpande, A., Kerby, J.T., **Graving, J.M.**, Costelloe, B.R., & Couzin, I.D. (2023). *Quantifying the movement, behaviour and environmental context of group-living animals using drones and computer vision.* **Journal of Animal Ecology**, 92(7), 1498â€“1515. [https://doi.org/10.1111/1365-2656.13904](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.13904)

<img src="https://raw.githubusercontent.com/benkoger/overhead-video-worked-examples/main/pictures/tracks_on_map_observation088.png" alt="Animal Tracks on Map" style="width:100%; margin-top:10px;">


## ðŸŸ **Vortex Phase Matching in Schooling Fish**  
A study employing deep learningâ€“based pose estimation and mechanistic modeling to test energy-optimization strategies in schooling fish.  
ðŸ”— [Publication](https://www.nature.com/articles/s41467-020-19086-0) | [Press Release](https://www.uni-konstanz.de/en/university/news-and-media/current-announcements/news-in-detail/roboter-helfen/)  
**ðŸ“„ Citation:**  
> Li, L., Nagy, M., **Graving, J.M.**, Bak-Coleman, J., Xie, G., & Couzin, I.D. (2020). *Vortex phase matching as a strategy for schooling in robots and in fish.* **Nature Communications**, 11, Article 5408. [https://doi.org/10.1038/s41467-020-19086-0](https://www.nature.com/articles/s41467-020-19086-0)


## ðŸ¤¸â€â™‚ï¸ **DeepPoseKit**  
A software toolkit for fast and robust animal pose estimation using deep learning.  
ðŸ”— [Code on GitHub](https://github.com/jgraving/DeepPoseKit) | [Publication](https://elifesciences.org/articles/47994)  
ðŸ“° Featured in: [Quanta Magazine](https://www.quantamagazine.org/to-decode-the-brain-scientists-automate-the-study-of-behavior-20191210/) | [Nature Methods](https://doi.org/10.1038/s41592-019-0678-2) | [Nature News & Views](https://doi.org/10.1038/d41586-019-02942-5)  
**ðŸ“„ Citation:**  
> **Graving, J.M.**, Chae, D., Naik, H., Li, L., Koger, B., Costelloe, B.R., Couzin, I.D. (2019). *DeepPoseKit, a software toolkit for fast and robust animal pose estimation using deep learning.* **eLife**, 8, e47994. [https://doi.org/10.7554/eLife.47994](https://elifesciences.org/articles/47994)

<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/Figure1video1.gif" alt="Swarm Pose" style="width:100%; margin-top:10px;">


## ðŸ¦ **Automated Barcode Tracking in Birds**  
Development of a low-cost, scalable system for tracking individual birds using backpack-mounted, machine-readable barcodes.  
This approach enabled automated identification, spatial tracking, and orientation detection in captive zebra finches, supporting the study of fine-scale behavior, social interactions, and network structure over extended timescales. The system integrates hardware, computer vision software, and custom code to process data efficiently and safely across entire groups.  
ðŸ”— [Publication](https://doi.org/10.1111/2041-210X.13005)  
**ðŸ“„ Citation:**  
> AlarcÃ³n-Nieto, G., **Graving, J.M.**, Klarevas-Irby, J.A., Maldonado-Chaparro, A.A., Mueller, I., & Farine, D.R. (2018). *An automated barcode tracking system for behavioural studies in birds.* **Methods in Ecology and Evolution**, 9(6), 1536â€“1547. [https://doi.org/10.1111/2041-210X.13005](https://doi.org/10.1111/2041-210X.13005)


## ðŸ•· **Navigation in Whip Spiders**  
Field and lab studies of spatial behavior and sensory integration in amblypygids (whip spiders), revealing their capacity for goal-directed navigation in complex, light-deprived environments.  
These experiments used radio telemetry, behavioral tracking, and sensory manipulation to study how olfactory and tactile cues â€” primarily from the antenniform legs â€” support navigation, even in the absence of vision.  
ðŸ”— [Journal of Experimental Biology (2017)](https://doi.org/10.1242/jeb.149823) | [Journal of Comparative Physiology A (2017)](https://doi.org/10.1007/s00359-017-1169-5) | [Frontiers in Behavioral Neuroscience (2016)](https://doi.org/10.3389/fnbeh.2016.00047)  
**ðŸ“„ Citations:**  
> **Graving, J.M.**, Bingman, V.P., Hebets, E.A., & Wiegmann, D.D. (2017). *Development of site fidelity in the nocturnal amblypygid, Phrynus marginemaculatus.* **Journal of Comparative Physiology A**, 203, 313â€“328. [https://doi.org/10.1007/s00359-017-1169-5](https://doi.org/10.1007/s00359-017-1169-5)  
>  
> Bingman, V.P., **Graving, J.M.**, Hebets, E.A., & Wiegmann, D.D. (2017). *Importance of the antenniform legs, but not vision, for homing by the neotropical whip spider Paraphrynus laevifrons.* **Journal of Experimental Biology**, 220, 885â€“890. [https://doi.org/10.1242/jeb.149823](https://doi.org/10.1242/jeb.149823)  
>  
> Wiegmann, D.D., Hebets, E.A., Gronenberg, W., **Graving, J.M.**, & Bingman, V.P. (2016). *Amblypygids: Model organisms for the study of arthropod navigation mechanisms in complex environments?* **Frontiers in Behavioral Neuroscience**, 10:47. [https://doi.org/10.3389/fnbeh.2016.00047](https://doi.org/10.3389/fnbeh.2016.00047)

<!-- 
Optional additional gifs:
<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/zebra.gif" alt="Zebra Pose Estimation" style="width:25%;">
<img src="https://raw.githubusercontent.com/jgraving/jgraving.github.io/master/files/images/locust.gif" alt="Locust Pose Estimation" style="width:25%;">
-->
